---
title: Real-time stateless dictation 
description: WebSocket Secure (WSS) API Documentation for stateless use of /transcribe endpoint for real-time speech-to-text  
tag: WSS
---

## Overview

The WebSocket Secure (WSS) API enables real-time, bidirectional communication with the Corti system for stateless speech-to-text. Clients can send and receive structured data, including transcripts and detected commands.

This documentation provides a comprehensive guide for integrating these capabilities.

<Info>
  This `/transcribe` endpoint supports real-time stateless dictation. 
  
  - If you are looking for real-time ambient documentation interactions, you should use the [/stream WSS](/api-reference/stream/)
  - If you are looking for asynchronous transcript generation as part of an interaction, then please refer to the [/transcripts endpoint](/api-reference/transcripts)
</Info>

### Environment Options

| Environment | Description |
| :--- | :--- |
| `us` | US-based instance |
| `eu` | EU-based instance |
| `beta-eu` | Beta EU instance (default) |

## Establishing a Connection <Icon icon="circle-wifi" iconType="solid" /> 

Clients must initiate a WebSocket connection using the `wss://` scheme.

<Note>When creating an interaction, the 200 response provides a `websocketUrl` for that interaction including the `tenant-name` as url parameter.
The authentication for the WSS stream requires in addition to the `tenant-name` parameter a `token` parameter to pass in the Bearer access token.</Note>

## Request 

### Query Parameters
<ParamField query="tenant-name" type="string" required>
  Specifies the tenant context
</ParamField>
<ParamField query="token" type="string" required>Bearer $token</ParamField>

```bash
  curl --request GET \
    --url wss://api.${environment}.corti.app/audio-bridge/v2/transcribe?tenant-name=${tenant}&token=Bearer%20${accessToken}
```

## Handshake Response

### **101 Switching Protocols** 

Indicates a successful WebSocket connection.
Upon successful connection, send a message including the configuration to specify the input and expected output formats.

```json
      {
  "type": "transcript",
  "data": {
    "text": "Hello.\nHow are you?",
    "rawTranscriptText": "hello new line how are you",
    "start": 0.124,
    "end": 6.421,
    "isFinal": true
  }
}
```
## Sending Messages <Icon icon="message-arrow-up" iconType="solid" /> 

Clients must send a stream configuration message and wait for a response of type `CONFIG_ACCEPTED` before transmitting other data.
If the configuration is not valid it will return `CONFIG_DENIED`.
The configuration must be committed within 10 seconds of opening the WebSocket, else it will time-out with `CONFIG_TIMEOUT`.

### Basic Stream Configuration

#### Body

<ParamField body="primaryLanguage" type="string" required>
  The locale of the primary spoken language. Check https://docs.corti.ai/about/languages for more.
</ParamField>
<ParamField body="interimResults" type="bool">
  When true, returns interim results for reduced latency
</ParamField>
<ParamField body="spokenPunctuation" type="bool">
  When true, converts spoken punctuation such as `period` or `slash` into `.`or `/`.
</ParamField>
<ParamField body="automaticPunctuation" type="bool">
  When true, automatically punctuates and capitalizes in the final transcript.
</ParamField>

### Advanced Stream Configuration: Commands
The transcribe endpoint supports registration and detection of commands, common in dictation workflows.
Extend the configuration with the following parameters to register commands that should be detected.

#### Body

<ParamField body="commands" type="command object[]">
  Provide the commands that should be registered and detected
   <Expandable title="command properties">
    <ParamField body="id" type="string" required>
      To identify the command when it gets detected and returned over the WebSocket
    </ParamField>
    <ParamField body="phrases" type="string[]">
      The spoken phrases that should trigger the command
    </ParamField>
    <ParamField body="variables" type="string[]">
      The spoken phrases that should trigger the command
    </ParamField>
    <Expandable title="variable properties">
        <ParamField body="key" type="string" required>
          To identify the command when it gets detected and returned over the WebSocket
        </ParamField>
        <ParamField body="type" type="string">
          The spoken phrases that should trigger the command
        </ParamField>
        <ParamField body="enum" type="string[]">
          The spoken phrases that should trigger the command
        </ParamField>
      </Expandable>
  </Expandable>
</ParamField>

Here is an example configuration for transcription of dictated audio in English, with interim results, spoken punctuation and automatic punctuation enabled, and example commands defined.
```jsx Configuration example
{
  primaryLanguage: "en",
  interimResults: true, 
  spokenPunctuation: true, 
  automaticPunctuation: true,
  commands: [
    {
      id: "next_section",
      phrases: ["next section", "go to next section"]
    },
    {
      id: "delete",
      phrases: ["delete that"]
    },
    {
            "id": "insert_template",
            "phrases": [
                "insert my {template_name} template",
                "insert {template_name} template"
            ],
            "variables": [
                {
                    "key": "template_name",
                    "type": "enum",
                    "enum": [
                        "radiology",
                        "referral"
                    ]
                }
            ]
    }
  ],
}
```

### Sending audio <Icon icon="microphone" iconType="solid" /> 
Raw audio data to be transcribed.

### Ending
To end the /transcribe session send a `type: end`. 
This will signal the server to send any remaining transcript segments and detected commands before the server sends a usage message
```json 
{
  "type":"usage",
  "credits":0.1
}
```
, then a message of type `ended`, and then closes.
## Responses <Icon icon="message-arrow-down" iconType="solid" /> 

### Configuration
<ResponseField name="type" type="string" required default="CONFIG_ACCEPTED">
  Returned when sending a valid configuration.
</ResponseField>
<ResponseField name="sessionId" type="uuid" required>
  Returned when sending a valid configuration.
</ResponseField>

### Transcripts
<ResponseField name="type" type="string" required default="transcript">
<ResponseField name="data" type="string" required></ResponseField>
      <Expandable title="data attributes" type="string" required>
        <ResponseField name="text" type="string" required>
          Transcript segment with punctuations applied and command phrases removed
        </ResponseField>
        <ResponseField name="rawTranscriptText" type="string" required>
          The raw transcript without spoken punctuation applied and without command phrases removed
        </ResponseField>
        <ResponseField name="start" type="float64" required>
          Start time of the transcript segment in seconds
        </ResponseField>
        <ResponseField name="end" type="float64" required>
          End time of the transcript segment in seconds
        </ResponseField>
        <ResponseField name="isFinal" type="bool" required>
          If false, then interim transcript result
        </ResponseField>
      </Expandable>
      </ResponseField>


### Commands
<ResponseField name="type" type="string" required default="command">
<ResponseField name="data" type="string" required></ResponseField>
      <Expandable title="data attributes" type="string" required>
        <ResponseField name="id" type="string" required>
          To identify the command when it gets detected and returned over the WebSocket
        </ResponseField>
        <ResponseField name="variables" type="string[]">
          The variables identified
        </ResponseField>
        <ResponseField name="rawTranscriptText" type="string" required>
          The raw transcript without spoken punctuation applied and without command phrases removed
        </ResponseField>
        <ResponseField name="start" type="float64" required>
          Start time of the transcript segment in seconds
        </ResponseField>
        <ResponseField name="end" type="float64" required>
          End time of the transcript segment in seconds
        </ResponseField>
      </Expandable>
</ResponseField>

```jsx Command response
      {
    "type": "command",
    "data": {
        "id": "insert_template",
        "variables": {
            "template_name": "radiology"
        },
        "rawTranscriptText": "insert my radiology template",
        "start": 2.3,
        "end": 2.9,
        }
      }
```

### Error Responses
<ResponseField name="type" type="string" required>
  Returned when sending an invalid configuration.
  
  Possible errors `CONFIG_DENIED`, `CONFIG_TIMEOUT`
</ResponseField>
<ResponseField name="reason" type="string">
  The reason the configuration is invalid.
</ResponseField>
<ResponseField name="sessionId" type="uuid" required>
  The session ID.
</ResponseField>

Once configuration has been accepted and the session is running, you may encounter runtime or application-level errors.
 These are sent as JSON objects with the following structure:

```json
{
  "type": "error",
  "error": {
    "id": "error id",
    "title": "error title",
    "status": 400,
    "detailsf": "error details",
    "doc":"link to documentation"
  }
}
```
In some cases, receiving an "error" type message will cause the stream to end and send a message of type `usage` and type `ENDED`.